{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14ceb836-a393-44c8-998a-de1638f4b06b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "project_dir = '/blue/shenhaowang/qingqisong/be-and-active-travel'\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef247771-e7bb-455b-a5b8-382921fec3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "Chicago Travel Behavior - Multi-Model Analysis (Transit Focus)\n",
    "================================================================================\n",
    "Purpose: Comprehensive statistical and machine learning analysis of TRANSIT\n",
    "         travel behavior determinants including built environment factors.\n",
    "\n",
    "Dependent Variables:\n",
    "    - Y_transit_duration_min (Continuous)\n",
    "    - n_transit_trips (Count)\n",
    "    - has_transit_travel (Binary)\n",
    "\n",
    "Models:\n",
    "    A. OLS Regression (Interpretability)\n",
    "    B. Gradient Boosting (Non-linear)\n",
    "    C. Random Forest (Robustness)\n",
    "    D. Poisson Regression (Count data - n_transit_trips)\n",
    "    E. Logistic Regression (Binary - has_transit_travel)\n",
    "\n",
    "\n",
    "================================================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60ea7d25-00dc-4807-b2b5-c7de1204aae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import PoissonRegressor, LogisticRegression\n",
    "from sklearn.metrics import (mean_absolute_error, mean_squared_error, r2_score,\n",
    "                             accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, roc_curve, confusion_matrix,\n",
    "                             classification_report)\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# Statsmodels imports\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.discrete.discrete_model import Logit, Poisson\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a26d77-cec6-4ae8-bde9-d349ab10c363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"    CHICAGO TRAVEL BEHAVIOR - TRANSIT ANALYSIS\")\n",
    "print(\"    芝加哥出行行为 - 公交出行分析\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "INPUT_FILE = './city_home_based_chicago_research_ready_v3_clean.csv'\n",
    "OUTPUT_DIR = './city_home_based_model_results_transit'\n",
    "\n",
    "import os\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Define variables\n",
    "DEPENDENT_VARS = {\n",
    "    'Y_transit_duration_min': 'continuous',\n",
    "    'n_transit_trips': 'count',\n",
    "    'has_transit_travel': 'binary'\n",
    "}\n",
    "\n",
    "DEMO_VARS = [\n",
    "    'age', 'Female', 'Employed', 'Bachelor_Above', \n",
    "    'hhinc', 'hhveh', 'Home_Owner', 'White', 'Black', 'Hispanic'\n",
    "]\n",
    "\n",
    "BE_VARS = [\n",
    "    'D1B', 'D1C', 'D2A_EPHHM', \n",
    "    'H_intersection_density', 'H_road_network_complexity', 'H_building_density',\n",
    "    'dist_cbd_mi', 'dist_rail_mi', 'dist_park_mi', 'bus_count_14mile'\n",
    "]\n",
    "\n",
    "INDEPENDENT_VARS = DEMO_VARS + BE_VARS\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Dependent Variables:\")\n",
    "for var, var_type in DEPENDENT_VARS.items():\n",
    "    print(f\"    - {var} ({var_type})\")\n",
    "print(f\"  Demographic Variables: {len(DEMO_VARS)}\")\n",
    "print(f\"  Built Environment Variables: {len(BE_VARS)}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[STEP 1] Loading Data / 加载数据\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "print(f\"\\n  Loaded: {len(df):,} observations\")\n",
    "\n",
    "# Select needed columns\n",
    "all_vars = list(DEPENDENT_VARS.keys()) + INDEPENDENT_VARS\n",
    "df_model = df[all_vars].copy().dropna()\n",
    "print(f\"  Final sample size: {len(df_model):,}\")\n",
    "\n",
    "# Check dependent variable distributions\n",
    "print(\"\\n  Dependent Variable Summary:\")\n",
    "for var, var_type in DEPENDENT_VARS.items():\n",
    "    data = df_model[var]\n",
    "    print(f\"\\n    {var} ({var_type}):\")\n",
    "    print(f\"      Mean: {data.mean():.2f}, Std: {data.std():.2f}\")\n",
    "    print(f\"      Min: {data.min():.0f}, Max: {data.max():.0f}\")\n",
    "    if var_type == 'binary':\n",
    "        print(f\"      Class 1: {data.sum():,} ({data.mean()*100:.1f}%)\")\n",
    "        print(f\"      Class 0: {(1-data).sum():,} ({(1-data.mean())*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6a924d-6a61-4170-a29f-1661db5b6976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: EXPLORATORY DATA ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[STEP 2] Exploratory Data Analysis / 探索性数据分析\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# Visualization 1: Distribution of Dependent Variables\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Y_transit_duration_min - Histogram\n",
    "ax = axes[0]\n",
    "data = df_model['Y_transit_duration_min']\n",
    "ax.hist(data[data > 0], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax.axvline(data[data > 0].mean(), color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Mean: {data[data > 0].mean():.1f}')\n",
    "ax.set_xlabel('Minutes')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Transit Duration (Non-Zero)\\n公交出行时长分布')\n",
    "ax.legend()\n",
    "\n",
    "# n_transit_trips - Count distribution\n",
    "ax = axes[1]\n",
    "data = df_model['n_transit_trips']\n",
    "counts = data.value_counts().sort_index()\n",
    "ax.bar(counts.index[:15], counts.values[:15], color='coral', edgecolor='black')\n",
    "ax.set_xlabel('Number of Trips')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Transit Trip Count\\n公交出行次数分布')\n",
    "\n",
    "# has_transit_travel - Pie chart\n",
    "ax = axes[2]\n",
    "data = df_model['has_transit_travel']\n",
    "sizes = [data.sum(), len(data) - data.sum()]\n",
    "labels = ['Has Transit\\n有公交出行', 'No Transit\\n无公交出行']\n",
    "colors = ['seagreen', 'lightgray']\n",
    "ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90,\n",
    "       explode=(0.05, 0))\n",
    "ax.set_title('Transit Travel Participation\\n公交出行参与率')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/01_transit_dv_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"\\n  ✓ Saved: 01_transit_dv_distributions.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# Visualization 2: Transit Use by Demographics\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "demo_binary = ['Female', 'Employed', 'Bachelor_Above', 'Home_Owner', \n",
    "               'White', 'Black', 'Hispanic', 'hhveh']\n",
    "\n",
    "for idx, var in enumerate(demo_binary):\n",
    "    row = idx // 4\n",
    "    col = idx % 4\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    if var == 'hhveh':\n",
    "        # Group by vehicle count\n",
    "        groups = df_model.groupby(var)['has_transit_travel'].mean() * 100\n",
    "        ax.bar(groups.index, groups.values, color='steelblue', edgecolor='black')\n",
    "        ax.set_xlabel('Vehicles')\n",
    "    else:\n",
    "        # Binary comparison\n",
    "        means = df_model.groupby(var)['has_transit_travel'].mean() * 100\n",
    "        ax.bar(['No', 'Yes'], means.values, color=['lightcoral', 'steelblue'], edgecolor='black')\n",
    "    \n",
    "    ax.set_ylabel('% Using Transit')\n",
    "    ax.set_title(f'Transit Use by {var}')\n",
    "\n",
    "plt.suptitle('Transit Travel Participation by Demographics\\n人口特征与公交出行参与率', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/02_transit_by_demographics.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"  ✓ Saved: 02_transit_by_demographics.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# Visualization 3: Transit Use by Built Environment\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Visualization 3: Transit Use by Built Environment\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "be_key_vars = ['D1B', 'dist_cbd_mi', 'dist_rail_mi', \n",
    "               'bus_count_14mile', 'D2A_EPHHM', 'H_building_density']\n",
    "\n",
    "for idx, var in enumerate(be_key_vars):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    try:\n",
    "        # Try qcut with duplicates='drop'\n",
    "        df_model['_quartile'] = pd.qcut(df_model[var], q=4, \n",
    "                                         labels=False, \n",
    "                                         duplicates='drop')\n",
    "        \n",
    "        # Create labels based on actual number of bins\n",
    "        n_bins = df_model['_quartile'].nunique()\n",
    "        \n",
    "        if n_bins >= 2:\n",
    "            # Transit participation by quartile\n",
    "            means = df_model.groupby('_quartile')['has_transit_travel'].mean() * 100\n",
    "            \n",
    "            colors = plt.cm.Blues(np.linspace(0.3, 0.9, len(means)))\n",
    "            bars = ax.bar(range(len(means)), means.values, color=colors, edgecolor='black')\n",
    "            ax.set_xticks(range(len(means)))\n",
    "            ax.set_xticklabels([f'Q{i+1}' for i in range(len(means))])\n",
    "            ax.set_ylabel('% Using Transit')\n",
    "            ax.set_xlabel(var)\n",
    "            ax.set_title(f'Transit Use by {var}')\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f'{var}\\nInsufficient variation', \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(f'{var}')\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Fallback: use median split\n",
    "        median_val = df_model[var].median()\n",
    "        df_model['_group'] = (df_model[var] > median_val).astype(int)\n",
    "        means = df_model.groupby('_group')['has_transit_travel'].mean() * 100\n",
    "        \n",
    "        ax.bar(['Below Median', 'Above Median'], means.values, \n",
    "               color=['lightblue', 'steelblue'], edgecolor='black')\n",
    "        ax.set_ylabel('% Using Transit')\n",
    "        ax.set_title(f'Transit Use by {var}')\n",
    "        \n",
    "        if '_group' in df_model.columns:\n",
    "            df_model.drop('_group', axis=1, inplace=True)\n",
    "    \n",
    "    # Clean up\n",
    "    if '_quartile' in df_model.columns:\n",
    "        df_model.drop('_quartile', axis=1, inplace=True)\n",
    "\n",
    "plt.suptitle('Transit Travel by Built Environment Characteristics\\n建成环境特征与公交出行', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/03_transit_by_be.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"  ✓ Saved: 03_transit_by_be.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# Visualization 4: Correlation Matrix\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "\n",
    "corr_vars = list(DEPENDENT_VARS.keys()) + INDEPENDENT_VARS\n",
    "corr_matrix = df_model[corr_vars].corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r',\n",
    "            center=0, square=True, linewidths=0.5, ax=ax,\n",
    "            annot_kws={'size': 7})\n",
    "\n",
    "ax.set_title('Correlation Matrix\\n相关系数矩阵', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/04_correlation_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"  ✓ Saved: 04_correlation_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa6b81a4-2d0e-4dc6-9c56-2a4b622cdae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: MULTICOLLINEARITY CHECK (VIF)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[STEP 3] Multicollinearity Check (VIF) / 多重共线性检验\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def calculate_vif(X):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['Variable'] = X.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_data.sort_values('VIF', ascending=False)\n",
    "\n",
    "X_vif = df_model[INDEPENDENT_VARS].copy()\n",
    "vif_df = calculate_vif(X_vif)\n",
    "\n",
    "print(\"\\n  Variance Inflation Factors:\")\n",
    "print(\"  \" + \"-\" * 50)\n",
    "\n",
    "high_vif_vars = []\n",
    "for _, row in vif_df.iterrows():\n",
    "    flag = \" ⚠ HIGH\" if row['VIF'] > 7 else \"\"\n",
    "    print(f\"  {row['Variable']:<35} {row['VIF']:>10.2f}{flag}\")\n",
    "    if row['VIF'] > 7:\n",
    "        high_vif_vars.append(row['Variable'])\n",
    "\n",
    "vif_df.to_csv(f'{OUTPUT_DIR}/vif_results.csv', index=False)\n",
    "\n",
    "# VIF Chart\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "colors = ['red' if v > 7 else 'steelblue' for v in vif_df['VIF']]\n",
    "ax.barh(vif_df['Variable'], vif_df['VIF'], color=colors, edgecolor='black')\n",
    "ax.axvline(x=7, color='red', linestyle='--', linewidth=2, label='VIF = 7 Threshold')\n",
    "ax.set_xlabel('Variance Inflation Factor')\n",
    "ax.set_title('Multicollinearity Check: VIF\\n多重共线性检验', fontsize=14)\n",
    "ax.legend()\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/05_vif_chart.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"\\n  ✓ Saved: 05_vif_chart.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b8c54b0-019c-42ce-b723-7a6dd46c6dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[STEP 4] Data Preprocessing / 数据预处理\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "binary_vars = ['Female', 'Employed', 'Bachelor_Above', 'Home_Owner', 'White', 'Black', 'Hispanic']\n",
    "continuous_vars = [v for v in INDEPENDENT_VARS if v not in binary_vars]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = df_model[INDEPENDENT_VARS].copy()\n",
    "X[continuous_vars] = scaler.fit_transform(X[continuous_vars])\n",
    "\n",
    "print(f\"  ✓ Standardized {len(continuous_vars)} continuous variables\")\n",
    "\n",
    "# Store all results\n",
    "all_results = {}\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: MODEL TRAINING - Loop through dependent variables\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[STEP 5] Model Training & Evaluation / 模型训练与评估\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for dep_var, var_type in DEPENDENT_VARS.items():\n",
    "    \n",
    "    print(f\"\\n\\n{'='*80}\")\n",
    "    print(f\"  DEPENDENT VARIABLE: {dep_var} ({var_type})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    y = df_model[dep_var].values\n",
    "    X_data = X.values\n",
    "    \n",
    "    # Train/Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_data, y, test_size=0.2, random_state=42, \n",
    "        stratify=y if var_type == 'binary' else None\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n  Train: {len(X_train):,}, Test: {len(X_test):,}\")\n",
    "    \n",
    "    results = []\n",
    "    models_dict = {}\n",
    "    predictions_dict = {}\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CONTINUOUS VARIABLE MODELS\n",
    "    # =========================================================================\n",
    "    if var_type == 'continuous':\n",
    "        \n",
    "        # Model A: OLS\n",
    "        print(f\"\\n  --- Model A: OLS Regression ---\")\n",
    "        X_train_sm = sm.add_constant(X_train)\n",
    "        X_test_sm = sm.add_constant(X_test)\n",
    "        \n",
    "        ols_model = sm.OLS(y_train, X_train_sm).fit()\n",
    "        y_pred_ols = ols_model.predict(X_test_sm)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred_ols)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred_ols))\n",
    "        r2 = r2_score(y_test, y_pred_ols)\n",
    "        \n",
    "        results.append({'Model': 'OLS', 'MAE': mae, 'RMSE': rmse, 'R2': r2})\n",
    "        models_dict['OLS'] = ols_model\n",
    "        predictions_dict['OLS'] = y_pred_ols\n",
    "        \n",
    "        print(f\"    R² = {r2:.4f}, MAE = {mae:.4f}, RMSE = {rmse:.4f}\")\n",
    "        \n",
    "        # Save OLS summary\n",
    "        with open(f'{OUTPUT_DIR}/ols_summary_{dep_var}.txt', 'w') as f:\n",
    "            f.write(ols_model.summary().as_text())\n",
    "        \n",
    "        # Model B: Gradient Boosting\n",
    "        print(f\"\\n  --- Model B: Gradient Boosting ---\")\n",
    "        gbdt = GradientBoostingRegressor(n_estimators=200, max_depth=5, \n",
    "                                          learning_rate=0.1, random_state=42)\n",
    "        gbdt.fit(X_train, y_train)\n",
    "        y_pred_gbdt = gbdt.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred_gbdt)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred_gbdt))\n",
    "        r2 = r2_score(y_test, y_pred_gbdt)\n",
    "        \n",
    "        results.append({'Model': 'GBDT', 'MAE': mae, 'RMSE': rmse, 'R2': r2})\n",
    "        models_dict['GBDT'] = gbdt\n",
    "        predictions_dict['GBDT'] = y_pred_gbdt\n",
    "        \n",
    "        print(f\"    R² = {r2:.4f}, MAE = {mae:.4f}, RMSE = {rmse:.4f}\")\n",
    "        \n",
    "        # Model C: Random Forest\n",
    "        print(f\"\\n  --- Model C: Random Forest ---\")\n",
    "        rf = RandomForestRegressor(n_estimators=200, max_depth=10, \n",
    "                                    min_samples_split=10, random_state=42, n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred_rf = rf.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "        r2 = r2_score(y_test, y_pred_rf)\n",
    "        \n",
    "        results.append({'Model': 'Random Forest', 'MAE': mae, 'RMSE': rmse, 'R2': r2})\n",
    "        models_dict['RF'] = rf\n",
    "        predictions_dict['RF'] = y_pred_rf\n",
    "        \n",
    "        print(f\"    R² = {r2:.4f}, MAE = {mae:.4f}, RMSE = {rmse:.4f}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # COUNT VARIABLE MODELS\n",
    "    # =========================================================================\n",
    "    elif var_type == 'count':\n",
    "        \n",
    "        # Model A: OLS (as baseline)\n",
    "        print(f\"\\n  --- Model A: OLS Regression ---\")\n",
    "        X_train_sm = sm.add_constant(X_train)\n",
    "        X_test_sm = sm.add_constant(X_test)\n",
    "        \n",
    "        ols_model = sm.OLS(y_train, X_train_sm).fit()\n",
    "        y_pred_ols = ols_model.predict(X_test_sm)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred_ols)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred_ols))\n",
    "        r2 = r2_score(y_test, y_pred_ols)\n",
    "        \n",
    "        results.append({'Model': 'OLS', 'MAE': mae, 'RMSE': rmse, 'R2': r2})\n",
    "        models_dict['OLS'] = ols_model\n",
    "        predictions_dict['OLS'] = y_pred_ols\n",
    "        \n",
    "        print(f\"    R² = {r2:.4f}, MAE = {mae:.4f}, RMSE = {rmse:.4f}\")\n",
    "        \n",
    "        with open(f'{OUTPUT_DIR}/ols_summary_{dep_var}.txt', 'w') as f:\n",
    "            f.write(ols_model.summary().as_text())\n",
    "        \n",
    "        # Model B: Poisson Regression\n",
    "        print(f\"\\n  --- Model B: Poisson Regression ---\")\n",
    "        try:\n",
    "            poisson = PoissonRegressor(alpha=0.1, max_iter=1000)\n",
    "            poisson.fit(X_train, y_train)\n",
    "            y_pred_poisson = poisson.predict(X_test)\n",
    "            \n",
    "            mae = mean_absolute_error(y_test, y_pred_poisson)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred_poisson))\n",
    "            r2 = r2_score(y_test, y_pred_poisson)\n",
    "            \n",
    "            results.append({'Model': 'Poisson', 'MAE': mae, 'RMSE': rmse, 'R2': r2})\n",
    "            models_dict['Poisson'] = poisson\n",
    "            predictions_dict['Poisson'] = y_pred_poisson\n",
    "            \n",
    "            print(f\"    R² = {r2:.4f}, MAE = {mae:.4f}, RMSE = {rmse:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    ⚠ Poisson failed: {e}\")\n",
    "        \n",
    "        # Model C: Gradient Boosting\n",
    "        print(f\"\\n  --- Model C: Gradient Boosting ---\")\n",
    "        gbdt = GradientBoostingRegressor(n_estimators=200, max_depth=5, \n",
    "                                          learning_rate=0.1, random_state=42)\n",
    "        gbdt.fit(X_train, y_train)\n",
    "        y_pred_gbdt = gbdt.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred_gbdt)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred_gbdt))\n",
    "        r2 = r2_score(y_test, y_pred_gbdt)\n",
    "        \n",
    "        results.append({'Model': 'GBDT', 'MAE': mae, 'RMSE': rmse, 'R2': r2})\n",
    "        models_dict['GBDT'] = gbdt\n",
    "        predictions_dict['GBDT'] = y_pred_gbdt\n",
    "        \n",
    "        print(f\"    R² = {r2:.4f}, MAE = {mae:.4f}, RMSE = {rmse:.4f}\")\n",
    "        \n",
    "        # Model D: Random Forest\n",
    "        print(f\"\\n  --- Model D: Random Forest ---\")\n",
    "        rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred_rf = rf.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "        r2 = r2_score(y_test, y_pred_rf)\n",
    "        \n",
    "        results.append({'Model': 'Random Forest', 'MAE': mae, 'RMSE': rmse, 'R2': r2})\n",
    "        models_dict['RF'] = rf\n",
    "        predictions_dict['RF'] = y_pred_rf\n",
    "        \n",
    "        print(f\"    R² = {r2:.4f}, MAE = {mae:.4f}, RMSE = {rmse:.4f}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # BINARY VARIABLE MODELS\n",
    "    # =========================================================================\n",
    "    elif var_type == 'binary':\n",
    "        \n",
    "        # Model A: Logistic Regression (statsmodels)\n",
    "        print(f\"\\n  --- Model A: Logistic Regression ---\")\n",
    "        X_train_sm = sm.add_constant(X_train)\n",
    "        X_test_sm = sm.add_constant(X_test)\n",
    "        \n",
    "        logit_model = Logit(y_train, X_train_sm).fit(disp=0)\n",
    "        y_pred_prob_logit = logit_model.predict(X_test_sm)\n",
    "        y_pred_logit = (y_pred_prob_logit >= 0.5).astype(int)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred_logit)\n",
    "        auc = roc_auc_score(y_test, y_pred_prob_logit)\n",
    "        f1 = f1_score(y_test, y_pred_logit)\n",
    "        \n",
    "        results.append({'Model': 'Logistic', 'Accuracy': acc, 'AUC': auc, 'F1': f1})\n",
    "        models_dict['Logistic'] = logit_model\n",
    "        predictions_dict['Logistic'] = y_pred_prob_logit\n",
    "        \n",
    "        print(f\"    Accuracy = {acc:.4f}, AUC = {auc:.4f}, F1 = {f1:.4f}\")\n",
    "        \n",
    "        with open(f'{OUTPUT_DIR}/logit_summary_{dep_var}.txt', 'w') as f:\n",
    "            f.write(logit_model.summary().as_text())\n",
    "        \n",
    "        # Model B: Gradient Boosting Classifier\n",
    "        print(f\"\\n  --- Model B: Gradient Boosting Classifier ---\")\n",
    "        gbdt_clf = GradientBoostingClassifier(n_estimators=200, max_depth=5, \n",
    "                                               learning_rate=0.1, random_state=42)\n",
    "        gbdt_clf.fit(X_train, y_train)\n",
    "        y_pred_prob_gbdt = gbdt_clf.predict_proba(X_test)[:, 1]\n",
    "        y_pred_gbdt = gbdt_clf.predict(X_test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred_gbdt)\n",
    "        auc = roc_auc_score(y_test, y_pred_prob_gbdt)\n",
    "        f1 = f1_score(y_test, y_pred_gbdt)\n",
    "        \n",
    "        results.append({'Model': 'GBDT', 'Accuracy': acc, 'AUC': auc, 'F1': f1})\n",
    "        models_dict['GBDT'] = gbdt_clf\n",
    "        predictions_dict['GBDT'] = y_pred_prob_gbdt\n",
    "        \n",
    "        print(f\"    Accuracy = {acc:.4f}, AUC = {auc:.4f}, F1 = {f1:.4f}\")\n",
    "        \n",
    "        # Model C: Random Forest Classifier\n",
    "        print(f\"\\n  --- Model C: Random Forest Classifier ---\")\n",
    "        rf_clf = RandomForestClassifier(n_estimators=200, max_depth=10, \n",
    "                                         min_samples_split=10, random_state=42, n_jobs=-1)\n",
    "        rf_clf.fit(X_train, y_train)\n",
    "        y_pred_prob_rf = rf_clf.predict_proba(X_test)[:, 1]\n",
    "        y_pred_rf = rf_clf.predict(X_test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred_rf)\n",
    "        auc = roc_auc_score(y_test, y_pred_prob_rf)\n",
    "        f1 = f1_score(y_test, y_pred_rf)\n",
    "        \n",
    "        results.append({'Model': 'Random Forest', 'Accuracy': acc, 'AUC': auc, 'F1': f1})\n",
    "        models_dict['RF'] = rf_clf\n",
    "        predictions_dict['RF'] = y_pred_prob_rf\n",
    "        \n",
    "        print(f\"    Accuracy = {acc:.4f}, AUC = {auc:.4f}, F1 = {f1:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    all_results[dep_var] = {\n",
    "        'type': var_type,\n",
    "        'results': pd.DataFrame(results),\n",
    "        'models': models_dict,\n",
    "        'predictions': predictions_dict,\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test\n",
    "    }\n",
    "    \n",
    "    # =========================================================================\n",
    "    # VISUALIZATIONS FOR THIS DEPENDENT VARIABLE\n",
    "    # =========================================================================\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Model Comparison Chart\n",
    "    if var_type in ['continuous', 'count']:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        for idx, metric in enumerate(['MAE', 'RMSE', 'R2']):\n",
    "            ax = axes[idx]\n",
    "            colors = plt.cm.Set2(np.linspace(0, 1, len(results_df)))\n",
    "            bars = ax.bar(results_df['Model'], results_df[metric], color=colors, edgecolor='black')\n",
    "            ax.set_ylabel(metric)\n",
    "            ax.set_title(f'{metric}')\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            for bar, val in zip(bars, results_df[metric]):\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "                       f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        fig.suptitle(f'Model Comparison: {dep_var}', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{OUTPUT_DIR}/06_model_comparison_{dep_var}.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "    else:  # binary\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        for idx, metric in enumerate(['Accuracy', 'AUC', 'F1']):\n",
    "            ax = axes[idx]\n",
    "            colors = plt.cm.Set2(np.linspace(0, 1, len(results_df)))\n",
    "            bars = ax.bar(results_df['Model'], results_df[metric], color=colors, edgecolor='black')\n",
    "            ax.set_ylabel(metric)\n",
    "            ax.set_title(f'{metric}')\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            for bar, val in zip(bars, results_df[metric]):\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "                       f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        fig.suptitle(f'Model Comparison: {dep_var}', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{OUTPUT_DIR}/06_model_comparison_{dep_var}.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"\\n  ✓ Saved: 06_model_comparison_{dep_var}.png\")\n",
    "    \n",
    "    # Feature Importance (Random Forest)\n",
    "    if 'RF' in models_dict:\n",
    "        rf_model = models_dict['RF']\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'Variable': INDEPENDENT_VARS,\n",
    "            'Importance': rf_model.feature_importances_\n",
    "        }).sort_values('Importance', ascending=True)\n",
    "        \n",
    "        colors = ['coral' if v in BE_VARS else 'steelblue' for v in importance_df['Variable']]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        ax.barh(importance_df['Variable'], importance_df['Importance'], color=colors, edgecolor='black')\n",
    "        ax.set_xlabel('Feature Importance')\n",
    "        ax.set_title(f'Random Forest Feature Importance: {dep_var}', fontsize=14)\n",
    "        \n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor='coral', edgecolor='black', label='Built Environment'),\n",
    "            Patch(facecolor='steelblue', edgecolor='black', label='Demographics')\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, loc='lower right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{OUTPUT_DIR}/07_feature_importance_{dep_var}.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"  ✓ Saved: 07_feature_importance_{dep_var}.png\")\n",
    "    \n",
    "    # ROC Curve (for binary)\n",
    "    if var_type == 'binary':\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        for model_name, y_pred_prob in predictions_dict.items():\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "            auc = roc_auc_score(y_test, y_pred_prob)\n",
    "            ax.plot(fpr, tpr, linewidth=2, label=f'{model_name} (AUC = {auc:.3f})')\n",
    "        \n",
    "        ax.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Guess')\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title(f'ROC Curve: {dep_var}', fontsize=14)\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.set_xlim([0, 1])\n",
    "        ax.set_ylim([0, 1])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{OUTPUT_DIR}/08_roc_curve_{dep_var}.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"  ✓ Saved: 08_roc_curve_{dep_var}.png\")\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        fig, axes = plt.subplots(1, len(predictions_dict), figsize=(5*len(predictions_dict), 5))\n",
    "        if len(predictions_dict) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx, (model_name, y_pred_prob) in enumerate(predictions_dict.items()):\n",
    "            y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            \n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
    "                       xticklabels=['No Transit', 'Transit'],\n",
    "                       yticklabels=['No Transit', 'Transit'])\n",
    "            axes[idx].set_xlabel('Predicted')\n",
    "            axes[idx].set_ylabel('Actual')\n",
    "            axes[idx].set_title(f'{model_name}')\n",
    "        \n",
    "        fig.suptitle(f'Confusion Matrices: {dep_var}', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{OUTPUT_DIR}/09_confusion_matrix_{dep_var}.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"  ✓ Saved: 09_confusion_matrix_{dep_var}.png\")\n",
    "    \n",
    "    # Partial Dependence Plots\n",
    "    if 'RF' in models_dict and var_type != 'binary':\n",
    "        rf_model = models_dict['RF']\n",
    "        key_be_indices = [INDEPENDENT_VARS.index(v) for v in ['D1B', 'dist_rail_mi', 'bus_count_14mile', 'dist_cbd_mi']]\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        PartialDependenceDisplay.from_estimator(\n",
    "            rf_model, X_train, features=key_be_indices,\n",
    "            feature_names=INDEPENDENT_VARS, ax=axes, kind='average'\n",
    "        )\n",
    "        fig.suptitle(f'Partial Dependence Plots: {dep_var}', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{OUTPUT_DIR}/10_pdp_{dep_var}.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"  ✓ Saved: 10_pdp_{dep_var}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b99c88d4-c2f7-4d10-84ca-9a0dee650558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: SUMMARY COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"[STEP 6] Summary Comparison / 综合比较\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Combine all results\n",
    "all_comparison = []\n",
    "for dep_var, data in all_results.items():\n",
    "    for _, row in data['results'].iterrows():\n",
    "        row_dict = row.to_dict()\n",
    "        row_dict['Dependent Variable'] = dep_var\n",
    "        row_dict['Type'] = data['type']\n",
    "        all_comparison.append(row_dict)\n",
    "\n",
    "comparison_df = pd.DataFrame(all_comparison)\n",
    "comparison_df.to_csv(f'{OUTPUT_DIR}/model_comparison_all.csv', index=False)\n",
    "\n",
    "print(\"\\n  All Model Results:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# Visualization: Overall Comparison\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Continuous/Count models - R²\n",
    "ax = axes[0]\n",
    "subset = comparison_df[comparison_df['Type'].isin(['continuous', 'count'])]\n",
    "if len(subset) > 0:\n",
    "    pivot = subset.pivot(index='Dependent Variable', columns='Model', values='R2')\n",
    "    pivot.plot(kind='bar', ax=ax, edgecolor='black')\n",
    "    ax.set_ylabel('R² Score')\n",
    "    ax.set_title('R² Comparison (Continuous/Count Outcomes)')\n",
    "    ax.legend(title='Model')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Binary models - AUC\n",
    "ax = axes[1]\n",
    "subset = comparison_df[comparison_df['Type'] == 'binary']\n",
    "if len(subset) > 0:\n",
    "    pivot = subset.pivot(index='Dependent Variable', columns='Model', values='AUC')\n",
    "    pivot.plot(kind='bar', ax=ax, edgecolor='black')\n",
    "    ax.set_ylabel('AUC Score')\n",
    "    ax.set_title('AUC Comparison (Binary Outcome)')\n",
    "    ax.legend(title='Model')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/11_overall_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"\\n  ✓ Saved: 11_overall_comparison.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# Visualization: Coefficient/Odds Ratio Comparison\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
    "\n",
    "for idx, (dep_var, data) in enumerate(all_results.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    if data['type'] == 'binary' and 'Logistic' in data['models']:\n",
    "        model = data['models']['Logistic']\n",
    "        coef_df = pd.DataFrame({\n",
    "            'Variable': INDEPENDENT_VARS,\n",
    "            'Coefficient': model.params[1:],\n",
    "            'Odds_Ratio': np.exp(model.params[1:]),\n",
    "            'P-value': model.pvalues[1:]\n",
    "        })\n",
    "    else:\n",
    "        model = data['models'].get('OLS')\n",
    "        if model:\n",
    "            coef_df = pd.DataFrame({\n",
    "                'Variable': INDEPENDENT_VARS,\n",
    "                'Coefficient': model.params[1:],\n",
    "                'P-value': model.pvalues[1:]\n",
    "            })\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    coef_df = coef_df.sort_values('Coefficient', ascending=True)\n",
    "    colors = ['green' if p < 0.05 else 'gray' for p in coef_df['P-value']]\n",
    "    \n",
    "    ax.barh(coef_df['Variable'], coef_df['Coefficient'], color=colors, edgecolor='black')\n",
    "    ax.axvline(0, color='black', linewidth=1)\n",
    "    ax.set_xlabel('Coefficient (Standardized)')\n",
    "    ax.set_title(f'{dep_var}')\n",
    "\n",
    "fig.suptitle('OLS/Logit Coefficients (Green = p < 0.05)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/12_coefficients_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"  ✓ Saved: 12_coefficients_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f726f9f2-7c69-4712-95b3-35d02eeee723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "    CHICAGO TRAVEL BEHAVIOR - TRANSIT ANALYSIS\n",
      "    芝加哥出行行为 - 公交出行分析\n",
      "================================================================================\n",
      "\n",
      "Configuration:\n",
      "  Dependent Variables:\n",
      "    - Y_transit_duration_min (continuous)\n",
      "    - n_transit_trips (count)\n",
      "    - has_transit_travel (binary)\n",
      "  Demographic Variables: 10\n",
      "  Built Environment Variables: 10\n",
      "\n",
      "================================================================================\n",
      "[STEP 1] Loading Data / 加载数据\n",
      "================================================================================\n",
      "\n",
      "  Loaded: 6,129 observations\n",
      "  Final sample size: 6,129\n",
      "\n",
      "  Dependent Variable Summary:\n",
      "\n",
      "    Y_transit_duration_min (continuous):\n",
      "      Mean: 31.77, Std: 56.61\n",
      "      Min: 0, Max: 960\n",
      "\n",
      "    n_transit_trips (count):\n",
      "      Mean: 0.68, Std: 0.95\n",
      "      Min: 0, Max: 8\n",
      "\n",
      "    has_transit_travel (binary):\n",
      "      Mean: 0.39, Std: 0.49\n",
      "      Min: 0, Max: 1\n",
      "      Class 1: 2,392 (39.0%)\n",
      "      Class 0: 3,737 (61.0%)\n",
      "\n",
      "================================================================================\n",
      "[STEP 2] Exploratory Data Analysis / 探索性数据分析\n",
      "================================================================================\n",
      "\n",
      "  ✓ Saved: 01_transit_dv_distributions.png\n",
      "  ✓ Saved: 02_transit_by_demographics.png\n",
      "  ✓ Saved: 03_transit_by_be.png\n",
      "  ✓ Saved: 04_correlation_matrix.png\n",
      "\n",
      "================================================================================\n",
      "[STEP 3] Multicollinearity Check (VIF) / 多重共线性检验\n",
      "================================================================================\n",
      "\n",
      "  Variance Inflation Factors:\n",
      "  --------------------------------------------------\n",
      "  H_road_network_complexity                38.27 ⚠ HIGH\n",
      "  hhinc                                    12.73 ⚠ HIGH\n",
      "  H_intersection_density                   11.91 ⚠ HIGH\n",
      "  H_building_density                       10.09 ⚠ HIGH\n",
      "  dist_cbd_mi                               7.87 ⚠ HIGH\n",
      "  age                                       7.07 ⚠ HIGH\n",
      "  White                                     6.52\n",
      "  D2A_EPHHM                                 5.71\n",
      "  Bachelor_Above                            5.38\n",
      "  Employed                                  5.08\n",
      "  bus_count_14mile                          4.68\n",
      "  dist_park_mi                              3.96\n",
      "  dist_rail_mi                              3.59\n",
      "  hhveh                                     3.20\n",
      "  Black                                     2.58\n",
      "  Home_Owner                                2.58\n",
      "  D1B                                       2.48\n",
      "  Female                                    2.19\n",
      "  Hispanic                                  1.38\n",
      "  D1C                                       1.31\n",
      "\n",
      "  ✓ Saved: 05_vif_chart.png\n",
      "\n",
      "================================================================================\n",
      "[STEP 4] Data Preprocessing / 数据预处理\n",
      "================================================================================\n",
      "  ✓ Standardized 13 continuous variables\n",
      "\n",
      "================================================================================\n",
      "[STEP 5] Model Training & Evaluation / 模型训练与评估\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "  DEPENDENT VARIABLE: Y_transit_duration_min (continuous)\n",
      "================================================================================\n",
      "\n",
      "  Train: 4,903, Test: 1,226\n",
      "\n",
      "  --- Model A: OLS Regression ---\n",
      "    R² = 0.0502, MAE = 37.4213, RMSE = 54.5750\n",
      "\n",
      "  --- Model B: Gradient Boosting ---\n",
      "    R² = 0.0100, MAE = 36.0728, RMSE = 55.7187\n",
      "\n",
      "  --- Model C: Random Forest ---\n",
      "    R² = 0.0401, MAE = 36.1516, RMSE = 54.8642\n",
      "\n",
      "  ✓ Saved: 06_model_comparison_Y_transit_duration_min.png\n",
      "  ✓ Saved: 07_feature_importance_Y_transit_duration_min.png\n",
      "  ✓ Saved: 10_pdp_Y_transit_duration_min.png\n",
      "\n",
      "\n",
      "================================================================================\n",
      "  DEPENDENT VARIABLE: n_transit_trips (count)\n",
      "================================================================================\n",
      "\n",
      "  Train: 4,903, Test: 1,226\n",
      "\n",
      "  --- Model A: OLS Regression ---\n",
      "    R² = 0.0702, MAE = 0.7428, RMSE = 0.8925\n",
      "\n",
      "  --- Model B: Poisson Regression ---\n",
      "    R² = 0.0782, MAE = 0.7482, RMSE = 0.8887\n",
      "\n",
      "  --- Model C: Gradient Boosting ---\n",
      "    R² = 0.0782, MAE = 0.7053, RMSE = 0.8887\n",
      "\n",
      "  --- Model D: Random Forest ---\n",
      "    R² = 0.0925, MAE = 0.7140, RMSE = 0.8818\n",
      "\n",
      "  ✓ Saved: 06_model_comparison_n_transit_trips.png\n",
      "  ✓ Saved: 07_feature_importance_n_transit_trips.png\n",
      "  ✓ Saved: 10_pdp_n_transit_trips.png\n",
      "\n",
      "\n",
      "================================================================================\n",
      "  DEPENDENT VARIABLE: has_transit_travel (binary)\n",
      "================================================================================\n",
      "\n",
      "  Train: 4,903, Test: 1,226\n",
      "\n",
      "  --- Model A: Logistic Regression ---\n",
      "    Accuracy = 0.6680, AUC = 0.7055, F1 = 0.4815\n",
      "\n",
      "  --- Model B: Gradient Boosting Classifier ---\n",
      "    Accuracy = 0.6794, AUC = 0.7192, F1 = 0.5559\n",
      "\n",
      "  --- Model C: Random Forest Classifier ---\n",
      "    Accuracy = 0.6949, AUC = 0.7422, F1 = 0.5180\n",
      "\n",
      "  ✓ Saved: 06_model_comparison_has_transit_travel.png\n",
      "  ✓ Saved: 07_feature_importance_has_transit_travel.png\n",
      "  ✓ Saved: 08_roc_curve_has_transit_travel.png\n",
      "  ✓ Saved: 09_confusion_matrix_has_transit_travel.png\n",
      "\n",
      "\n",
      "================================================================================\n",
      "[STEP 6] Summary Comparison / 综合比较\n",
      "================================================================================\n",
      "\n",
      "  All Model Results:\n",
      "        Model       MAE      RMSE       R2     Dependent Variable       Type  Accuracy      AUC       F1\n",
      "          OLS 37.421290 54.574999 0.050222 Y_transit_duration_min continuous       NaN      NaN      NaN\n",
      "         GBDT 36.072810 55.718663 0.009998 Y_transit_duration_min continuous       NaN      NaN      NaN\n",
      "Random Forest 36.151591 54.864201 0.040129 Y_transit_duration_min continuous       NaN      NaN      NaN\n",
      "          OLS  0.742755  0.892540 0.070224        n_transit_trips      count       NaN      NaN      NaN\n",
      "      Poisson  0.748162  0.888694 0.078220        n_transit_trips      count       NaN      NaN      NaN\n",
      "         GBDT  0.705291  0.888703 0.078202        n_transit_trips      count       NaN      NaN      NaN\n",
      "Random Forest  0.713962  0.881782 0.092502        n_transit_trips      count       NaN      NaN      NaN\n",
      "     Logistic       NaN       NaN      NaN     has_transit_travel     binary  0.668026 0.705523 0.481529\n",
      "         GBDT       NaN       NaN      NaN     has_transit_travel     binary  0.679445 0.719226 0.555932\n",
      "Random Forest       NaN       NaN      NaN     has_transit_travel     binary  0.694943 0.742195 0.518041\n",
      "\n",
      "  ✓ Saved: 11_overall_comparison.png\n",
      "  ✓ Saved: 12_coefficients_comparison.png\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY / 最终总结\n",
      "================================================================================\n",
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                    TRANSIT ANALYSIS COMPLETE                                 ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "  Analysis Overview / 分析概览:\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "    Sample Size:              6,129\n",
      "    Dependent Variables:      3 (1 continuous, 1 count, 1 binary)\n",
      "    Independent Variables:    20\n",
      "\n",
      "  Best Models by Outcome / 各因变量最佳模型:\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "    Y_transit_duration_min:\n",
      "      Best: OLS (R² = 0.0502)\n",
      "    n_transit_trips:\n",
      "      Best: Random Forest (R² = 0.0925)\n",
      "    has_transit_travel:\n",
      "      Best: Random Forest (AUC = 0.7422)\n",
      "\n",
      "  Output Files / 输出文件:\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "    Directory: ./city_home_based_model_results_transit/\n",
      "    \n",
      "    ✓ vif_results.csv\n",
      "    ✓ model_comparison_all.csv\n",
      "    ✓ ols_summary_*.txt / logit_summary_*.txt\n",
      "    ✓ 01-12 visualization PNGs\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════════════\n",
      "                         ✓ ANALYSIS COMPLETE\n",
      "══════════════════════════════════════════════════════════════════════════════\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY / 最终总结\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════════════╗\n",
    "║                    TRANSIT ANALYSIS COMPLETE                                 ║\n",
    "╚══════════════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "  Analysis Overview / 分析概览:\n",
    "  ────────────────────────────────────────────────────────────────────────────\n",
    "    Sample Size:              {len(df_model):,}\n",
    "    Dependent Variables:      3 (1 continuous, 1 count, 1 binary)\n",
    "    Independent Variables:    {len(INDEPENDENT_VARS)}\n",
    "\n",
    "  Best Models by Outcome / 各因变量最佳模型:\n",
    "  ────────────────────────────────────────────────────────────────────────────\n",
    "\"\"\")\n",
    "\n",
    "for dep_var, data in all_results.items():\n",
    "    results = data['results']\n",
    "    if data['type'] == 'binary':\n",
    "        best = results.loc[results['AUC'].idxmax()]\n",
    "        print(f\"    {dep_var}:\")\n",
    "        print(f\"      Best: {best['Model']} (AUC = {best['AUC']:.4f})\")\n",
    "    else:\n",
    "        best = results.loc[results['R2'].idxmax()]\n",
    "        print(f\"    {dep_var}:\")\n",
    "        print(f\"      Best: {best['Model']} (R² = {best['R2']:.4f})\")\n",
    "\n",
    "print(f\"\"\"\n",
    "  Output Files / 输出文件:\n",
    "  ────────────────────────────────────────────────────────────────────────────\n",
    "    Directory: {OUTPUT_DIR}/\n",
    "    \n",
    "    ✓ vif_results.csv\n",
    "    ✓ model_comparison_all.csv\n",
    "    ✓ ols_summary_*.txt / logit_summary_*.txt\n",
    "    ✓ 01-12 visualization PNGs\n",
    "\n",
    "══════════════════════════════════════════════════════════════════════════════\n",
    "                         ✓ ANALYSIS COMPLETE\n",
    "══════════════════════════════════════════════════════════════════════════════\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d94ae97-e919-4f05-8636-8dd1c79e295e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
